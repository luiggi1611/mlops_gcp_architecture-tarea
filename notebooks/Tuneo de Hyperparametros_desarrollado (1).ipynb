{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "757d83f6",
   "metadata": {},
   "source": [
    "# La optimización de hiperparámetros\n",
    "\n",
    "Es un paso crítico en el proceso de construcción de modelos de aprendizaje automático. Los hiperparámetros son variables que afectan el rendimiento del modelo pero que no se aprenden directamente a partir de los datos. Algunos ejemplos de hiperparámetros comunes son la tasa de aprendizaje en algoritmos de aprendizaje profundo, la profundidad máxima en árboles de decisión y el parámetro C en SVM.\n",
    "\n",
    "El proceso de optimización de hiperparámetros implica buscar la combinación óptima de hiperparámetros que maximice el rendimiento del modelo en un conjunto de datos de prueba. Hay varias estrategias que se pueden utilizar para la optimización de hiperparámetros, incluyendo la búsqueda de cuadrícula, la búsqueda aleatoria y la optimización bayesiana.\n",
    "\n",
    "La búsqueda de cuadrícula es una estrategia de optimización de hiperparámetros exhaustiva que implica probar todas las combinaciones posibles de hiperparámetros en una cuadrícula predefinida. La búsqueda aleatoria, por otro lado, implica seleccionar aleatoriamente combinaciones de hiperparámetros dentro de un rango predefinido.\n",
    "\n",
    "La optimización bayesiana es una estrategia de optimización de hiperparámetros más avanzada que utiliza un modelo probabilístico para modelar la relación entre los hiperparámetros y el rendimiento del modelo. En lugar de probar todas las combinaciones de hiperparámetros, la optimización bayesiana utiliza la información recopilada en iteraciones anteriores para guiar la selección de hiperparámetros en iteraciones futuras.\n",
    "\n",
    "En Python, hay varias bibliotecas que pueden ayudar con la optimización de hiperparámetros, incluyendo Scikit-Learn, Keras-Tuner y Optuna. Scikit-Learn proporciona varias herramientas de búsqueda de cuadrícula y búsqueda aleatoria, mientras que Keras-Tuner y Optuna proporcionan herramientas más avanzadas de optimización de hiperparámetros, incluyendo la optimización bayesiana.\n",
    "\n",
    "En general, la optimización de hiperparámetros es un paso crítico en el proceso de construcción de modelos de aprendizaje automático. Las estrategias de optimización de hiperparámetros pueden variar desde enfoques simples de búsqueda de cuadrícula hasta técnicas más avanzadas de optimización bayesiana. Al elegir una estrategia de optimización de hiperparámetros, es importante tener en cuenta el tiempo de procesamiento, la complejidad del modelo y el tamaño de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db381e9",
   "metadata": {},
   "source": [
    "## Búsqueda en cuadrícula (grid search):\n",
    "La búsqueda en cuadrícula es una técnica de optimización de hiperparámetros que implica la exploración sistemática de todas las combinaciones posibles de valores de hiperparámetros en una cuadrícula predefinida. Por ejemplo, si estamos ajustando un modelo SVM, podemos querer ajustar los valores de los parámetros \"C\" y \"gamma\". Podemos definir una cuadrícula de valores para cada hiperparámetro y probar todas las combinaciones posibles para encontrar los mejores valores. Aquí hay un ejemplo de cómo hacer una búsqueda en cuadrícula en Scikit-Learn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9dc659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Mejores parámetros:  {'C': 1, 'gamma': 0.1}\n",
      "Mejor puntaje:  0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Cargamos el dataset de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Definimos los parámetros que queremos optimizar\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}\n",
    "\n",
    "# Creamos un objeto de clasificador SVM\n",
    "svc = SVC()\n",
    "\n",
    "# Realizamos la búsqueda en cuadrícula con validación cruzada de 5-fold\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, verbose=True)\n",
    "\n",
    "# Entrenamos el modelo con los datos de entrenamiento\n",
    "grid_search.fit(iris.data, iris.target)\n",
    "\n",
    "# Imprimimos los mejores parámetros y el mejor puntaje\n",
    "print(\"Mejores parámetros: \", grid_search.best_params_)\n",
    "print(\"Mejor puntaje: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c62a7f",
   "metadata": {},
   "source": [
    "## Búsqueda aleatoria (random search):\n",
    "La búsqueda aleatoria es una técnica de optimización de hiperparámetros que implica la exploración aleatoria de valores de hiperparámetros dentro de un rango predefinido. A diferencia de la búsqueda en cuadrícula, la búsqueda aleatoria no examina todas las combinaciones posibles de valores de hiperparámetros. En su lugar, selecciona aleatoriamente combinaciones de hiperparámetros para evaluar. Aquí hay un ejemplo de cómo hacer una búsqueda aleatoria en Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78983a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Mejores parámetros:  {'n_estimators': 200, 'max_depth': 9}\n",
      "Mejor puntaje:  0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "# Cargamos el dataset de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Definimos los parámetros que queremos optimizar\n",
    "param_distributions = {'n_estimators': np.arange(100, 1000, 100),\n",
    "                       'max_depth': [3, 5, 7, 9]}\n",
    "\n",
    "# Creamos un objeto de clasificador de bosque aleatorio\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Realizamos la búsqueda aleatoria con validación cruzada de 5-fold\n",
    "random_search = RandomizedSearchCV(rf, param_distributions, cv=5, verbose=True, n_iter=3)\n",
    "\n",
    "# Entrenamos el modelo con los datos de entrenamiento\n",
    "random_search.fit(iris.data, iris.target)\n",
    "\n",
    "# Imprimimos los mejores parámetros y el mejor puntaje\n",
    "print(\"Mejores parámetros: \", random_search.best_params_)\n",
    "print(\"Mejor puntaje: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4285b",
   "metadata": {},
   "source": [
    "## Optimización bayesiana:\n",
    "La optimización bayesiana es una técnica de optimización de hiperparámetros más avanzada que utiliza un modelo probabilístico para modelar a relación entre los hiperparámetros y el rendimiento del modelo y determinar qué combinaciones de hiperparámetros son más prometedoras para explorar. En lugar de evaluar todas las combinaciones posibles de valores de hiperparámetros, la optimización bayesiana se centra en las combinaciones que son más probables de mejorar el rendimiento del modelo.\n",
    "\n",
    "Aquí hay un ejemplo de cómo realizar una optimización bayesiana de hiperparámetros en Python utilizando la biblioteca de optimización bayesiana BayesianOptimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc47c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e76f9251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.96     \u001b[0m | \u001b[0m5.622    \u001b[0m | \u001b[0m0.9547   \u001b[0m | \u001b[0m7.856    \u001b[0m | \u001b[0m638.8    \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.9667   \u001b[0m | \u001b[95m4.092    \u001b[0m | \u001b[95m0.2402   \u001b[0m | \u001b[95m2.465    \u001b[0m | \u001b[95m879.6    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.96     \u001b[0m | \u001b[0m7.208    \u001b[0m | \u001b[0m0.7366   \u001b[0m | \u001b[0m2.165    \u001b[0m | \u001b[0m972.9    \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.96     \u001b[0m | \u001b[0m8.827    \u001b[0m | \u001b[0m0.2909   \u001b[0m | \u001b[0m3.455    \u001b[0m | \u001b[0m265.1    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.96     \u001b[0m | \u001b[0m5.13     \u001b[0m | \u001b[0m0.5718   \u001b[0m | \u001b[0m5.456    \u001b[0m | \u001b[0m362.1    \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.9667   \u001b[0m | \u001b[0m4.09     \u001b[0m | \u001b[0m0.3423   \u001b[0m | \u001b[0m2.799    \u001b[0m | \u001b[0m878.6    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.96     \u001b[0m | \u001b[0m9.93     \u001b[0m | \u001b[0m0.3652   \u001b[0m | \u001b[0m2.056    \u001b[0m | \u001b[0m790.9    \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.9533   \u001b[0m | \u001b[0m4.598    \u001b[0m | \u001b[0m0.8969   \u001b[0m | \u001b[0m5.238    \u001b[0m | \u001b[0m100.1    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.9667   \u001b[0m | \u001b[0m9.892    \u001b[0m | \u001b[0m0.8162   \u001b[0m | \u001b[0m9.669    \u001b[0m | \u001b[0m502.5    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.9533   \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m0.1      \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m453.0    \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.9667   \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m0.999    \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m528.8    \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.9533   \u001b[0m | \u001b[0m3.105    \u001b[0m | \u001b[0m0.6758   \u001b[0m | \u001b[0m2.823    \u001b[0m | \u001b[0m571.8    \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.96     \u001b[0m | \u001b[0m9.723    \u001b[0m | \u001b[0m0.7853   \u001b[0m | \u001b[0m9.281    \u001b[0m | \u001b[0m915.4    \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.96     \u001b[0m | \u001b[0m9.291    \u001b[0m | \u001b[0m0.2086   \u001b[0m | \u001b[0m2.064    \u001b[0m | \u001b[0m842.3    \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m0.9533   \u001b[0m | \u001b[0m3.911    \u001b[0m | \u001b[0m0.4026   \u001b[0m | \u001b[0m2.349    \u001b[0m | \u001b[0m515.4    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.96     \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m0.7441   \u001b[0m | \u001b[0m10.0     \u001b[0m | \u001b[0m495.6    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.96     \u001b[0m | \u001b[0m8.813    \u001b[0m | \u001b[0m0.7118   \u001b[0m | \u001b[0m9.937    \u001b[0m | \u001b[0m534.7    \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.9667   \u001b[0m | \u001b[0m7.086    \u001b[0m | \u001b[0m0.4753   \u001b[0m | \u001b[0m6.321    \u001b[0m | \u001b[0m880.4    \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.96     \u001b[0m | \u001b[0m9.833    \u001b[0m | \u001b[0m0.4403   \u001b[0m | \u001b[0m2.815    \u001b[0m | \u001b[0m878.2    \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.96     \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m0.999    \u001b[0m | \u001b[0m7.187    \u001b[0m | \u001b[0m880.9    \u001b[0m |\n",
      "=========================================================================\n",
      "Mejores parámetros:  {'max_depth': 4.092130483097056, 'max_features': 0.24023907378224618, 'min_samples_split': 2.4646688973455957, 'n_estimators': 879.5585311974417}\n",
      "Mejor puntaje:  0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Cargamos el dataset de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Definimos la función objetivo que queremos maximizar\n",
    "def rf_cv(n_estimators, max_depth, min_samples_split, max_features):\n",
    "    \"\"\"\n",
    "    Función para optimizar los hiperparámetros de un clasificador de bosque aleatorio\n",
    "    utilizando validación cruzada.\n",
    "    \"\"\"\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=int(n_estimators),\n",
    "        max_depth=int(max_depth),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        max_features=max(min(max_features, 0.999), 1e-3),\n",
    "        random_state=42,\n",
    "    )\n",
    "    return cross_val_score(clf, iris.data, iris.target, cv=5).mean()\n",
    "\n",
    "# Definimos los rangos de valores para los hiperparámetros que queremos optimizar\n",
    "pbounds = {\n",
    "    'n_estimators': (100, 1000),\n",
    "    'max_depth': (3, 10),\n",
    "    'min_samples_split': (2, 10),\n",
    "    'max_features': (0.1, 0.999),\n",
    "}\n",
    "\n",
    "# Creamos un objeto de optimización bayesiana\n",
    "optimizer = BayesianOptimization(\n",
    "    f=rf_cv,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Realizamos la optimización bayesiana durante 20 iteraciones\n",
    "optimizer.maximize(init_points=5, n_iter=15)\n",
    "\n",
    "# Imprimimos los mejores parámetros y el mejor puntaje\n",
    "print(\"Mejores parámetros: \", optimizer.max[\"params\"])\n",
    "print(\"Mejor puntaje: \", optimizer.max[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3963db8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from optuna) (2.0.7)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from optuna) (1.23.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from optuna) (1.10.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\lsilvaa\\pycharmprojects\\certusenero2023\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79607c76",
   "metadata": {},
   "source": [
    "### Ejemplo de ajuste de hiperparámetros con Optuna para un problema de clasificación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "111cc0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 20:39:20,299]\u001b[0m A new study created in memory with name: no-name-f153fced-194b-4c19-afb9-80437c598922\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:21,086]\u001b[0m Trial 0 finished with value: 0.8866666666666667 and parameters: {'n_estimators': 93, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.8866666666666667.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:21,350]\u001b[0m Trial 1 finished with value: 0.9 and parameters: {'n_estimators': 20, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.9.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:22,151]\u001b[0m Trial 2 finished with value: 0.91 and parameters: {'n_estimators': 72, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.91.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:22,354]\u001b[0m Trial 3 finished with value: 0.89 and parameters: {'n_estimators': 12, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.91.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:23,032]\u001b[0m Trial 4 finished with value: 0.83 and parameters: {'n_estimators': 90, 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 2 with value: 0.91.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:23,466]\u001b[0m Trial 5 finished with value: 0.83 and parameters: {'n_estimators': 54, 'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 2 with value: 0.91.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:23,783]\u001b[0m Trial 6 finished with value: 0.89 and parameters: {'n_estimators': 24, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.91.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:23,970]\u001b[0m Trial 7 finished with value: 0.8933333333333333 and parameters: {'n_estimators': 16, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.91.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:24,434]\u001b[0m Trial 8 finished with value: 0.89 and parameters: {'n_estimators': 39, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.91.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:24,800]\u001b[0m Trial 9 finished with value: 0.9066666666666666 and parameters: {'n_estimators': 30, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.91.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:25,769]\u001b[0m Trial 10 finished with value: 0.9133333333333333 and parameters: {'n_estimators': 76, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 10 with value: 0.9133333333333333.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:26,716]\u001b[0m Trial 11 finished with value: 0.9166666666666666 and parameters: {'n_estimators': 71, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.9166666666666666.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:27,670]\u001b[0m Trial 12 finished with value: 0.91 and parameters: {'n_estimators': 75, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.9166666666666666.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:28,529]\u001b[0m Trial 13 finished with value: 0.9166666666666666 and parameters: {'n_estimators': 69, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9166666666666666.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:29,212]\u001b[0m Trial 14 finished with value: 0.91 and parameters: {'n_estimators': 60, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9166666666666666.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:29,785]\u001b[0m Trial 15 finished with value: 0.9033333333333333 and parameters: {'n_estimators': 56, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.9166666666666666.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:30,161]\u001b[0m Trial 16 finished with value: 0.88 and parameters: {'n_estimators': 45, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.9166666666666666.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:31,010]\u001b[0m Trial 17 finished with value: 0.9133333333333333 and parameters: {'n_estimators': 83, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9166666666666666.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:31,629]\u001b[0m Trial 18 finished with value: 0.91 and parameters: {'n_estimators': 67, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.9166666666666666.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:32,551]\u001b[0m Trial 19 finished with value: 0.93 and parameters: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:33,696]\u001b[0m Trial 20 finished with value: 0.9166666666666666 and parameters: {'n_estimators': 98, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:34,870]\u001b[0m Trial 21 finished with value: 0.93 and parameters: {'n_estimators': 86, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:35,973]\u001b[0m Trial 22 finished with value: 0.91 and parameters: {'n_estimators': 84, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:37,061]\u001b[0m Trial 23 finished with value: 0.9133333333333333 and parameters: {'n_estimators': 85, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:38,261]\u001b[0m Trial 24 finished with value: 0.91 and parameters: {'n_estimators': 100, 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:39,180]\u001b[0m Trial 25 finished with value: 0.9033333333333333 and parameters: {'n_estimators': 80, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:39,921]\u001b[0m Trial 26 finished with value: 0.91 and parameters: {'n_estimators': 64, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:40,961]\u001b[0m Trial 27 finished with value: 0.9066666666666666 and parameters: {'n_estimators': 91, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:42,051]\u001b[0m Trial 28 finished with value: 0.9166666666666666 and parameters: {'n_estimators': 78, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:43,149]\u001b[0m Trial 29 finished with value: 0.9066666666666666 and parameters: {'n_estimators': 94, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:43,965]\u001b[0m Trial 30 finished with value: 0.8833333333333333 and parameters: {'n_estimators': 88, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:44,830]\u001b[0m Trial 31 finished with value: 0.9166666666666666 and parameters: {'n_estimators': 69, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:45,565]\u001b[0m Trial 32 finished with value: 0.89 and parameters: {'n_estimators': 62, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:46,482]\u001b[0m Trial 33 finished with value: 0.91 and parameters: {'n_estimators': 72, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:47,100]\u001b[0m Trial 34 finished with value: 0.8933333333333333 and parameters: {'n_estimators': 47, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:48,002]\u001b[0m Trial 35 finished with value: 0.91 and parameters: {'n_estimators': 71, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:49,233]\u001b[0m Trial 36 finished with value: 0.91 and parameters: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.93.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 20:39:50,265]\u001b[0m Trial 37 finished with value: 0.9133333333333333 and parameters: {'n_estimators': 79, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:51,330]\u001b[0m Trial 38 finished with value: 0.9066666666666666 and parameters: {'n_estimators': 88, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:52,033]\u001b[0m Trial 39 finished with value: 0.9066666666666666 and parameters: {'n_estimators': 51, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:52,819]\u001b[0m Trial 40 finished with value: 0.8933333333333333 and parameters: {'n_estimators': 66, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:54,020]\u001b[0m Trial 41 finished with value: 0.9133333333333333 and parameters: {'n_estimators': 97, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:55,070]\u001b[0m Trial 42 finished with value: 0.91 and parameters: {'n_estimators': 82, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:56,332]\u001b[0m Trial 43 finished with value: 0.9266666666666666 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:57,520]\u001b[0m Trial 44 finished with value: 0.9133333333333333 and parameters: {'n_estimators': 87, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:58,591]\u001b[0m Trial 45 finished with value: 0.9166666666666666 and parameters: {'n_estimators': 74, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:39:59,899]\u001b[0m Trial 46 finished with value: 0.9133333333333333 and parameters: {'n_estimators': 91, 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:40:00,700]\u001b[0m Trial 47 finished with value: 0.9033333333333333 and parameters: {'n_estimators': 59, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:40:01,677]\u001b[0m Trial 48 finished with value: 0.89 and parameters: {'n_estimators': 76, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 19 with value: 0.93.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 20:40:02,840]\u001b[0m Trial 49 finished with value: 0.9033333333333333 and parameters: {'n_estimators': 100, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.93.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiperparámetros óptimos: {'n_estimators': 85, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generar datos sintéticos para clasificación\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir la función objetivo para optimizar\n",
    "def objective(trial):\n",
    "    # Definir los rangos de búsqueda de los hiperparámetros\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    # Crear un clasificador Random Forest con los hiperparámetros seleccionados\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  min_samples_split=min_samples_split,\n",
    "                                  min_samples_leaf=min_samples_leaf,\n",
    "                                  random_state=42)\n",
    "    \n",
    "    # Entrenar y evaluar el modelo\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Crear un objeto de estudio Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Ejecutar la optimización de hiperparámetros\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Obtener los hiperparámetros óptimos\n",
    "best_params = study.best_params\n",
    "print(f'Hiperparámetros óptimos: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99889896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 17:21:53,943]\u001b[0m A new study created in memory with name: no-name-7024258d-4b85-4bbf-979a-84d272b75b09\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:53,953]\u001b[0m Trial 0 finished with value: 4660.865325519481 and parameters: {'alpha': 317.1199910892221, 'max_iter': 313, 'tol': 2.394393219804691e-05}. Best is trial 0 with value: 4660.865325519481.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:53,959]\u001b[0m Trial 1 finished with value: 9.963273189550617e-08 and parameters: {'alpha': 0.0009711770666913667, 'max_iter': 349, 'tol': 2.626210392829354e-05}. Best is trial 1 with value: 9.963273189550617e-08.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:53,965]\u001b[0m Trial 2 finished with value: 1.1671603101400753e-10 and parameters: {'alpha': 3.3240075155941936e-05, 'max_iter': 357, 'tol': 2.157871611054754e-05}. Best is trial 2 with value: 1.1671603101400753e-10.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:53,970]\u001b[0m Trial 3 finished with value: 1161.9532056764733 and parameters: {'alpha': 126.22285233508887, 'max_iter': 149, 'tol': 0.017984664303124443}. Best is trial 2 with value: 1.1671603101400753e-10.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:53,975]\u001b[0m Trial 4 finished with value: 3.9276510310476414 and parameters: {'alpha': 6.1583680699961345, 'max_iter': 184, 'tol': 2.2724254715607074e-05}. Best is trial 2 with value: 1.1671603101400753e-10.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:53,980]\u001b[0m Trial 5 finished with value: 1.2286249433518603 and parameters: {'alpha': 3.4293172842763653, 'max_iter': 653, 'tol': 0.0016451992499431458}. Best is trial 2 with value: 1.1671603101400753e-10.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:53,984]\u001b[0m Trial 6 finished with value: 5.362008103933024 and parameters: {'alpha': 7.207615375621304, 'max_iter': 501, 'tol': 0.035400650973674376}. Best is trial 2 with value: 1.1671603101400753e-10.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:53,988]\u001b[0m Trial 7 finished with value: 5.2336645173427756e-08 and parameters: {'alpha': 0.0007038824738221465, 'max_iter': 923, 'tol': 0.0076512079359716}. Best is trial 2 with value: 1.1671603101400753e-10.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:53,992]\u001b[0m Trial 8 finished with value: 8.561892572189296e-05 and parameters: {'alpha': 0.02847092628152512, 'max_iter': 876, 'tol': 6.548536998383434e-05}. Best is trial 2 with value: 1.1671603101400753e-10.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:53,999]\u001b[0m Trial 9 finished with value: 10699.408330748842 and parameters: {'alpha': 649.2804220766293, 'max_iter': 143, 'tol': 0.01975950581312955}. Best is trial 2 with value: 1.1671603101400753e-10.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,021]\u001b[0m Trial 10 finished with value: 1.2555064999858736e-11 and parameters: {'alpha': 1.0902000801239068e-05, 'max_iter': 646, 'tol': 0.0002279619607881251}. Best is trial 10 with value: 1.2555064999858736e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,043]\u001b[0m Trial 11 finished with value: 2.7287452803573226e-11 and parameters: {'alpha': 1.6072307417018255e-05, 'max_iter': 618, 'tol': 0.00017334725154098652}. Best is trial 10 with value: 1.2555064999858736e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,063]\u001b[0m Trial 12 finished with value: 3.20381937016202e-11 and parameters: {'alpha': 1.7415291270864146e-05, 'max_iter': 722, 'tol': 0.0001995993379573984}. Best is trial 10 with value: 1.2555064999858736e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,079]\u001b[0m Trial 13 finished with value: 1.7382896202170845e-11 and parameters: {'alpha': 1.2827965890178177e-05, 'max_iter': 585, 'tol': 0.00036983506474042667}. Best is trial 10 with value: 1.2555064999858736e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,100]\u001b[0m Trial 14 finished with value: 1.033874941601264e-08 and parameters: {'alpha': 0.0003128462412940438, 'max_iter': 769, 'tol': 0.0008598223739578821}. Best is trial 10 with value: 1.2555064999858736e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,120]\u001b[0m Trial 15 finished with value: 6.609751323228869e-06 and parameters: {'alpha': 0.007910334198824871, 'max_iter': 489, 'tol': 0.0005458560546222232}. Best is trial 10 with value: 1.2555064999858736e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,140]\u001b[0m Trial 16 finished with value: 8.152121328619526e-10 and parameters: {'alpha': 8.784804405774198e-05, 'max_iter': 829, 'tol': 0.002721333234185269}. Best is trial 10 with value: 1.2555064999858736e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,162]\u001b[0m Trial 17 finished with value: 1.0931674848402104e-11 and parameters: {'alpha': 1.0172790029449267e-05, 'max_iter': 1000, 'tol': 0.00034388235419001743}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,185]\u001b[0m Trial 18 finished with value: 1.454925476880552e-06 and parameters: {'alpha': 0.0037112456160226376, 'max_iter': 974, 'tol': 9.428356056354241e-05}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,208]\u001b[0m Trial 19 finished with value: 2.112701369385487e-09 and parameters: {'alpha': 0.00014142164140932767, 'max_iter': 753, 'tol': 0.09830550840219414}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,233]\u001b[0m Trial 20 finished with value: 1.9627207776864947e-09 and parameters: {'alpha': 0.00013630948380421632, 'max_iter': 1000, 'tol': 0.0019401071893517603}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,261]\u001b[0m Trial 21 finished with value: 3.4353081421269216e-11 and parameters: {'alpha': 1.803348165456634e-05, 'max_iter': 588, 'tol': 0.00039745510237325696}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,286]\u001b[0m Trial 22 finished with value: 2.135065067942914e-11 and parameters: {'alpha': 1.4216814213024823e-05, 'max_iter': 455, 'tol': 0.0003128700561183231}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,316]\u001b[0m Trial 23 finished with value: 5.460764334175499e-10 and parameters: {'alpha': 7.189910527323224e-05, 'max_iter': 673, 'tol': 0.0006447187928844165}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,342]\u001b[0m Trial 24 finished with value: 2.916028226604007e-08 and parameters: {'alpha': 0.0005254034833467446, 'max_iter': 548, 'tol': 7.776115820112047e-05}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,383]\u001b[0m Trial 25 finished with value: 1.4317509673705404e-11 and parameters: {'alpha': 1.1642077147232707e-05, 'max_iter': 431, 'tol': 0.0002681446820207779}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,407]\u001b[0m Trial 26 finished with value: 2.834914408057354e-10 and parameters: {'alpha': 5.180440974803113e-05, 'max_iter': 417, 'tol': 0.00014219840383532302}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,432]\u001b[0m Trial 27 finished with value: 6.269311080527262e-07 and parameters: {'alpha': 0.0024361741901312963, 'max_iter': 255, 'tol': 0.001103857503895474}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,452]\u001b[0m Trial 28 finished with value: 4.436536438002063e-09 and parameters: {'alpha': 0.00020493629833895753, 'max_iter': 851, 'tol': 5.708735012674368e-05}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,477]\u001b[0m Trial 29 finished with value: 1.7359156423639314e-10 and parameters: {'alpha': 4.053788214080279e-05, 'max_iter': 264, 'tol': 0.00023817790684427354}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,508]\u001b[0m Trial 30 finished with value: 1.428559770849782e-07 and parameters: {'alpha': 0.0011629117046163561, 'max_iter': 405, 'tol': 0.00012256413021422677}. Best is trial 17 with value: 1.0931674848402104e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,535]\u001b[0m Trial 31 finished with value: 1.0896796479941902e-11 and parameters: {'alpha': 1.015654845458343e-05, 'max_iter': 547, 'tol': 0.0004327224190628553}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,558]\u001b[0m Trial 32 finished with value: 1.2847247067133011e-11 and parameters: {'alpha': 1.1028126996672772e-05, 'max_iter': 545, 'tol': 0.0005147860340763835}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,581]\u001b[0m Trial 33 finished with value: 2.9017994798777936e-10 and parameters: {'alpha': 5.241196639012717e-05, 'max_iter': 526, 'tol': 0.0005542559236215861}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,614]\u001b[0m Trial 34 finished with value: 6.24195886218163e-09 and parameters: {'alpha': 0.0002430845398550506, 'max_iter': 335, 'tol': 0.0010479312297884283}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,640]\u001b[0m Trial 35 finished with value: 1.1333182324799366e-10 and parameters: {'alpha': 3.275462845597728e-05, 'max_iter': 676, 'tol': 3.6993438550796626e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,673]\u001b[0m Trial 36 finished with value: 3.8880953088443614e-10 and parameters: {'alpha': 6.066877292001321e-05, 'max_iter': 780, 'tol': 0.00011400432823180055}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,705]\u001b[0m Trial 37 finished with value: 1.2579209468355111e-11 and parameters: {'alpha': 1.0912478461029031e-05, 'max_iter': 375, 'tol': 1.0506509457846422e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,728]\u001b[0m Trial 38 finished with value: 1.832151897192062e-08 and parameters: {'alpha': 0.0004164642702453203, 'max_iter': 283, 'tol': 1.2113012173295367e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,754]\u001b[0m Trial 39 finished with value: 2.498825297214709e-09 and parameters: {'alpha': 0.0001538029878082579, 'max_iter': 195, 'tol': 1.0828632118489088e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,785]\u001b[0m Trial 40 finished with value: 1.6497135773522534e-07 and parameters: {'alpha': 0.001249688775378405, 'max_iter': 390, 'tol': 4.140125090857267e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,814]\u001b[0m Trial 41 finished with value: 1.246439889948923e-11 and parameters: {'alpha': 1.0862565219510483e-05, 'max_iter': 496, 'tol': 1.7656250806737834e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,847]\u001b[0m Trial 42 finished with value: 9.661378263507814e-11 and parameters: {'alpha': 3.02424019953206e-05, 'max_iter': 486, 'tol': 1.8135783195351334e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,877]\u001b[0m Trial 43 finished with value: 1.0368244261510802e-10 and parameters: {'alpha': 3.132920325194746e-05, 'max_iter': 366, 'tol': 2.5330345155006e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,907]\u001b[0m Trial 44 finished with value: 5.332583871159326e-10 and parameters: {'alpha': 7.105025064901529e-05, 'max_iter': 610, 'tol': 3.507497125315206e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,938]\u001b[0m Trial 45 finished with value: 1.4306028496843873e-11 and parameters: {'alpha': 1.1637408404838784e-05, 'max_iter': 922, 'tol': 1.4618449921627616e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:54,971]\u001b[0m Trial 46 finished with value: 1.3683206922630806e-09 and parameters: {'alpha': 0.00011381270461681599, 'max_iter': 102, 'tol': 1.765161962572602e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:55,008]\u001b[0m Trial 47 finished with value: 5.281984160749174e-11 and parameters: {'alpha': 2.2361209025042028e-05, 'max_iter': 315, 'tol': 1.0387217493210923e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:55,039]\u001b[0m Trial 48 finished with value: 9.042354957381294e-11 and parameters: {'alpha': 2.92575202118286e-05, 'max_iter': 478, 'tol': 0.00016692911161752833}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
      "C:\\Users\\lsilvaa\\AppData\\Local\\Temp\\ipykernel_18436\\1410408502.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
      "\u001b[32m[I 2023-03-29 17:21:55,083]\u001b[0m Trial 49 finished with value: 1.2462857433295778e-08 and parameters: {'alpha': 0.00034348341476262583, 'max_iter': 649, 'tol': 5.726315564678045e-05}. Best is trial 31 with value: 1.0896796479941902e-11.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiperparámetros óptimos: {'alpha': 1.015654845458343e-05, 'max_iter': 547, 'tol': 0.0004327224190628553}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generar datos sintéticos para regresión\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=10, random_state=42)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir la función objetivo para optimizar\n",
    "def objective(trial):\n",
    "     #metros\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-5, 1e3)\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000)\n",
    "    tol = trial.suggest_loguniform('tol', 1e-5, 1e-1)\n",
    "    \n",
    "    # Crear un modelo de regresión Ridge con los hiperparámetros seleccionados\n",
    "    reg = Ridge(alpha=alpha, max_iter=max_iter, tol=tol, random_state=42)\n",
    "    \n",
    "    # Entrenar y evaluar el modelo\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "# Crear un objeto de estudio Optuna\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# Ejecutar la optimización de hiperparámetros\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Obtener los hiperparámetros óptimos\n",
    "best_params = study.best_params\n",
    "print(f'Hiperparámetros óptimos: {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8faeb91",
   "metadata": {},
   "source": [
    "## ACTIVIDAD\n",
    "\n",
    "Optimicemos los modelos de la claseanterior utilizando el codigo de hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89d9db2",
   "metadata": {},
   "source": [
    "1. Recolectar y preparar los datos: Es importante recopilar los datos relevantes y prepararlos adecuadamente antes de poder comenzar a entrenar un modelo de machine learning. Esto puede incluir la limpieza de los datos, la normalización, la selección de características y la división de los datos en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "2. Seleccionar un algoritmo de aprendizaje automático: Hay muchos tipos diferentes de algoritmos de aprendizaje automático, cada uno de los cuales se adapta mejor a diferentes tipos de datos y problemas. Por lo tanto, es importante elegir el algoritmo adecuado para el problema específico que estás tratando de resolver.\n",
    "\n",
    "3. Entrenar el modelo: Una vez que hayas seleccionado el algoritmo de aprendizaje automático, es hora de entrenar el modelo. Esto implica alimentar los datos de entrenamiento al modelo y ajustar los parámetros para que el modelo pueda hacer predicciones precisas.\n",
    "\n",
    "4. Evaluar el modelo: Después de entrenar el modelo, es importante evaluar su rendimiento en los datos de prueba. Esto puede implicar el cálculo de métricas como la precisión, la sensibilidad y la especificidad.\n",
    "    \n",
    "5. Ajustar los hiperparámetros: Una vez que hayas seleccionado el algoritmo de aprendizaje automático, es posible que necesites ajustar los hiperparámetros del modelo para obtener el mejor rendimiento posible. Los hiperparámetros son valores que se establecen antes de entrenar el modelo y afectan cómo se ajusta el modelo a los datos. Puedes ajustar los hiperparámetros mediante la búsqueda de cuadrícula, la búsqueda aleatoria, la optimización bayesiana u otros métodos.\n",
    "\n",
    "6. Evaluar el modelo con los datos de validación: Después de ajustar los hiperparámetros, es importante evaluar el rendimiento del modelo utilizando un conjunto de datos de validación que no se haya utilizado en el entrenamiento ni en la evaluación. Esto puede ayudarte a seleccionar los mejores hiperparámetros y a evitar el sobreajuste.\n",
    "\n",
    "7. Entrenar el modelo final: Después de ajustar los hiperparámetros y evaluar el modelo con los datos de validación, es hora de entrenar el modelo final utilizando todos los datos de entrenamiento disponibles.\n",
    "\n",
    "8. Desplegar el modelo: Una vez que hayas entrenado el modelo final, es posible que desees desplegarlo en un entorno de producción para hacer predicciones en tiempo real. Esto puede implicar la creación de una API, un servicio web o una aplicación móvil que pueda conectarse con el modelo y hacer predicciones en función de los nuevos datos que se ingresen.\n",
    "\n",
    "9. Monitorear y mantener el modelo: Una vez que el modelo se ha desplegado, es importante monitorear su rendimiento y realizar mantenimiento periódico. Esto puede implicar la actualización del modelo con nuevos datos o ajustes de hiperparámetros para mantener el rendimiento óptimo del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7232a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   output  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARGAR la Data\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"heart.csv\",usecols =['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n",
    "       'exng', 'oldpeak', 'slp',  'output'] )\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee570574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.express as px\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\",None)\n",
    "from sklearn import preprocessing\n",
    "import matplotlib \n",
    "matplotlib.style.use('ggplot')\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e81b465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   29    1   3      31    64    1        0        49     0       22    0   \n",
       "1    3    1   2      22    80    0        1        84     0       32    0   \n",
       "2    7    0   1      22    35    0        0        71     0       14    2   \n",
       "3   22    1   1      14    67    0        1        76     0        8    2   \n",
       "4   23    0   0      14   145    0        1        62     1        6    2   \n",
       "\n",
       "   output  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tree = df.apply(LabelEncoder().fit_transform)\n",
    "df_tree.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "923632d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
      "Logistic Regression  0.791209   0.750000  0.893617  0.815534  0.787718\n",
      "Decision Tree        0.593407   0.596154  0.659574  0.626263  0.591151\n",
      "Random Forest        0.758242   0.727273  0.851064  0.784314  0.755077\n",
      "Gradient Boosting    0.714286   0.705882  0.765957  0.734694  0.712524\n",
      "AdaBoost             0.714286   0.698113  0.787234  0.740000  0.711799\n",
      "XGBoost              0.725275   0.720000  0.765957  0.742268  0.723888\n",
      "LightGBM             0.747253   0.722222  0.829787  0.772277  0.744439\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "# Carga los datos\n",
    "data = df_tree.copy()\n",
    "X = data[['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n",
    "       'exng', 'oldpeak', 'slp']]\n",
    "y = data[\"output\"]\n",
    "\n",
    "# División de los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Entrenamiento y evaluación de los modelos\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"XGBoost\": xgb.XGBClassifier(),\n",
    "    \"LightGBM\": lgb.LGBMClassifier()\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC AUC\"])\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    results.loc[name] = [accuracy, precision, recall, f1, roc_auc]\n",
    "\n",
    "# Muestra los resultados\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9854078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros:  {'C': 1, 'penalty': 'l2'}\n",
      "Mejor puntaje:  0.7925802879291252\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "\n",
    "# Definimos los parámetros que queremos optimizar\n",
    "param_grid = {'C': [0.1, 1, 10], 'penalty': [\"l1\",\"l2\"]}\n",
    "\n",
    "# Creamos un objeto de clasificador Logistic Regression\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Realizamos la búsqueda en cuadrícula con validación cruzada de 5-fold\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# Entrenamos el modelo con los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimimos los mejores parámetros y el mejor puntaje\n",
    "print(\"Mejores parámetros: \", grid_search.best_params_)\n",
    "print(\"Mejor puntaje: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e9eafb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 22:30:57,822]\u001b[0m A new study created in memory with name: no-name-21e71153-f0f6-40f9-a2d0-8cc8ff1b129f\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:57,860]\u001b[0m Trial 0 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 37, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:57,892]\u001b[0m Trial 1 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 33, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:57,944]\u001b[0m Trial 2 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 49, 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:57,960]\u001b[0m Trial 3 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 12, 'max_depth': 4, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,027]\u001b[0m Trial 4 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 68, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,104]\u001b[0m Trial 5 finished with value: 0.7912087912087912 and parameters: {'n_estimators': 90, 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,141]\u001b[0m Trial 6 finished with value: 0.7582417582417582 and parameters: {'n_estimators': 35, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,174]\u001b[0m Trial 7 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 31, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,201]\u001b[0m Trial 8 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 27, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,258]\u001b[0m Trial 9 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 66, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,351]\u001b[0m Trial 10 finished with value: 0.7472527472527473 and parameters: {'n_estimators': 95, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,383]\u001b[0m Trial 11 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 20, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,451]\u001b[0m Trial 12 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,497]\u001b[0m Trial 13 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 41, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,528]\u001b[0m Trial 14 finished with value: 0.8131868131868132 and parameters: {'n_estimators': 21, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,550]\u001b[0m Trial 15 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 12, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,613]\u001b[0m Trial 16 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 62, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,683]\u001b[0m Trial 17 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 80, 'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,712]\u001b[0m Trial 18 finished with value: 0.8131868131868132 and parameters: {'n_estimators': 23, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,761]\u001b[0m Trial 19 finished with value: 0.7912087912087912 and parameters: {'n_estimators': 22, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,816]\u001b[0m Trial 20 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 45, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 10}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,851]\u001b[0m Trial 21 finished with value: 0.8131868131868132 and parameters: {'n_estimators': 21, 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,884]\u001b[0m Trial 22 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 20, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,910]\u001b[0m Trial 23 finished with value: 0.7472527472527473 and parameters: {'n_estimators': 10, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,952]\u001b[0m Trial 24 finished with value: 0.8131868131868132 and parameters: {'n_estimators': 25, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:58,980]\u001b[0m Trial 25 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 16, 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,043]\u001b[0m Trial 26 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 57, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,085]\u001b[0m Trial 27 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 31, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,139]\u001b[0m Trial 28 finished with value: 0.7912087912087912 and parameters: {'n_estimators': 42, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,176]\u001b[0m Trial 29 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 27, 'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,228]\u001b[0m Trial 30 finished with value: 0.7912087912087912 and parameters: {'n_estimators': 38, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,259]\u001b[0m Trial 31 finished with value: 0.8131868131868132 and parameters: {'n_estimators': 24, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,295]\u001b[0m Trial 32 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 17, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,343]\u001b[0m Trial 33 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 28, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 22:30:59,379]\u001b[0m Trial 34 finished with value: 0.8131868131868132 and parameters: {'n_estimators': 16, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,425]\u001b[0m Trial 35 finished with value: 0.7472527472527473 and parameters: {'n_estimators': 36, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,460]\u001b[0m Trial 36 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 24, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,544]\u001b[0m Trial 37 finished with value: 0.7912087912087912 and parameters: {'n_estimators': 77, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,612]\u001b[0m Trial 38 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 50, 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,656]\u001b[0m Trial 39 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 33, 'max_depth': 2, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,676]\u001b[0m Trial 40 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 11, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,722]\u001b[0m Trial 41 finished with value: 0.8131868131868132 and parameters: {'n_estimators': 25, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,758]\u001b[0m Trial 42 finished with value: 0.7912087912087912 and parameters: {'n_estimators': 20, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,794]\u001b[0m Trial 43 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 28, 'max_depth': 7, 'min_samples_split': 4, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,827]\u001b[0m Trial 44 finished with value: 0.7912087912087912 and parameters: {'n_estimators': 15, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,877]\u001b[0m Trial 45 finished with value: 0.8131868131868132 and parameters: {'n_estimators': 32, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,916]\u001b[0m Trial 46 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 23, 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:30:59,964]\u001b[0m Trial 47 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 39, 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:31:00,006]\u001b[0m Trial 48 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 19, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:31:00,076]\u001b[0m Trial 49 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 45, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.8131868131868132.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiperparámetros óptimos: {'n_estimators': 21, 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 4}\n"
     ]
    }
   ],
   "source": [
    "#Optimizando el random\n",
    "import optuna\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Definir la función objetivo para optimizar\n",
    "def objective(trial):\n",
    "    # Definir los rangos de búsqueda de los hiperparámetros\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    # Crear un clasificador Random Forest con los hiperparámetros seleccionados\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  min_samples_split=min_samples_split,\n",
    "                                  min_samples_leaf=min_samples_leaf,\n",
    "                                  random_state=42)\n",
    "    \n",
    "    # Entrenar y evaluar el modelo\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Crear un objeto de estudio Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Ejecutar la optimización de hiperparámetros\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Obtener los hiperparámetros óptimos\n",
    "best_params = study.best_params\n",
    "print(f'Hiperparámetros óptimos: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99191320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "763faa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=16, min_samples_leaf=10, min_samples_split=6,\n",
       "                       n_estimators=12)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=16, min_samples_leaf=10, min_samples_split=6,\n",
       "                       n_estimators=12)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=16, min_samples_leaf=10, min_samples_split=6,\n",
       "                       n_estimators=12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf_tun = RandomForestClassifier(n_estimators = 12, max_depth = 16, min_samples_split = 6, min_samples_leaf = 10)\n",
    "model_rf_tun.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4fafb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bdcf9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rf_tun.predict(X_test)\n",
    "accuracy_rf_tun = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9986c75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7472527472527473 0.7802197802197802\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_rf,accuracy_rf_tun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e93db802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lg = LogisticRegression()\n",
    "model_lg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6eb488b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lg_tun = LogisticRegression(C = 1, penalty = 'l2')\n",
    "model_lg_tun.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75bca830",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lg.predict(X_test)\n",
    "accuracy_lg = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a2fa935",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lg_tun.predict(X_test)\n",
    "accuracy_lg_tun = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b244c07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7912087912087912 0.7912087912087912\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_lg,accuracy_lg_tun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d25b8692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7472527472527473 0.7802197802197802\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_rf,accuracy_rf_tun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5cd0963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 22:32:32,554]\u001b[0m A new study created in memory with name: no-name-80840fb4-1254-40cb-a7b1-60efc5ee7020\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,576]\u001b[0m Trial 0 finished with value: 0.7142857142857143 and parameters: {'n_estimators': 13, 'max_depth': 6, 'min_child_samples': 5}. Best is trial 0 with value: 0.7142857142857143.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,609]\u001b[0m Trial 1 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 75, 'max_depth': 3, 'min_child_samples': 3}. Best is trial 1 with value: 0.7692307692307693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,632]\u001b[0m Trial 2 finished with value: 0.6923076923076923 and parameters: {'n_estimators': 25, 'max_depth': 7, 'min_child_samples': 10}. Best is trial 1 with value: 0.7692307692307693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,649]\u001b[0m Trial 3 finished with value: 0.7582417582417582 and parameters: {'n_estimators': 33, 'max_depth': 4, 'min_child_samples': 10}. Best is trial 1 with value: 0.7692307692307693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,663]\u001b[0m Trial 4 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 10, 'max_depth': 6, 'min_child_samples': 9}. Best is trial 1 with value: 0.7692307692307693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,703]\u001b[0m Trial 5 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 97, 'max_depth': 7, 'min_child_samples': 10}. Best is trial 1 with value: 0.7692307692307693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,738]\u001b[0m Trial 6 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 32, 'max_depth': 6, 'min_child_samples': 2}. Best is trial 1 with value: 0.7692307692307693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,773]\u001b[0m Trial 7 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 79, 'max_depth': 9, 'min_child_samples': 10}. Best is trial 1 with value: 0.7692307692307693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,812]\u001b[0m Trial 8 finished with value: 0.7472527472527473 and parameters: {'n_estimators': 83, 'max_depth': 7, 'min_child_samples': 8}. Best is trial 1 with value: 0.7692307692307693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,876]\u001b[0m Trial 9 finished with value: 0.7252747252747253 and parameters: {'n_estimators': 92, 'max_depth': 8, 'min_child_samples': 4}. Best is trial 1 with value: 0.7692307692307693.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,905]\u001b[0m Trial 10 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 61, 'max_depth': 2, 'min_child_samples': 2}. Best is trial 10 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,932]\u001b[0m Trial 11 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 60, 'max_depth': 2, 'min_child_samples': 2}. Best is trial 10 with value: 0.8021978021978022.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,963]\u001b[0m Trial 12 finished with value: 0.8131868131868132 and parameters: {'n_estimators': 57, 'max_depth': 2, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:32,996]\u001b[0m Trial 13 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 56, 'max_depth': 4, 'min_child_samples': 6}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,022]\u001b[0m Trial 14 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 48, 'max_depth': 2, 'min_child_samples': 4}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,069]\u001b[0m Trial 15 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 67, 'max_depth': 3, 'min_child_samples': 3}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,099]\u001b[0m Trial 16 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 48, 'max_depth': 4, 'min_child_samples': 7}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,144]\u001b[0m Trial 17 finished with value: 0.7472527472527473 and parameters: {'n_estimators': 45, 'max_depth': 10, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,171]\u001b[0m Trial 18 finished with value: 0.7912087912087912 and parameters: {'n_estimators': 68, 'max_depth': 2, 'min_child_samples': 4}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,207]\u001b[0m Trial 19 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 64, 'max_depth': 5, 'min_child_samples': 6}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,238]\u001b[0m Trial 20 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 42, 'max_depth': 3, 'min_child_samples': 3}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,266]\u001b[0m Trial 21 finished with value: 0.8131868131868132 and parameters: {'n_estimators': 59, 'max_depth': 2, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,293]\u001b[0m Trial 22 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 53, 'max_depth': 2, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,325]\u001b[0m Trial 23 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 72, 'max_depth': 3, 'min_child_samples': 3}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,361]\u001b[0m Trial 24 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 58, 'max_depth': 5, 'min_child_samples': 5}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,387]\u001b[0m Trial 25 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 40, 'max_depth': 2, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,422]\u001b[0m Trial 26 finished with value: 0.7582417582417582 and parameters: {'n_estimators': 86, 'max_depth': 3, 'min_child_samples': 3}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,453]\u001b[0m Trial 27 finished with value: 0.7472527472527473 and parameters: {'n_estimators': 53, 'max_depth': 4, 'min_child_samples': 4}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,496]\u001b[0m Trial 28 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 61, 'max_depth': 5, 'min_child_samples': 5}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,520]\u001b[0m Trial 29 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 21, 'max_depth': 2, 'min_child_samples': 5}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,558]\u001b[0m Trial 30 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 71, 'max_depth': 3, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,587]\u001b[0m Trial 31 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 62, 'max_depth': 2, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,621]\u001b[0m Trial 32 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 76, 'max_depth': 2, 'min_child_samples': 3}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,655]\u001b[0m Trial 33 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 53, 'max_depth': 3, 'min_child_samples': 3}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,696]\u001b[0m Trial 34 finished with value: 0.7582417582417582 and parameters: {'n_estimators': 59, 'max_depth': 4, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,726]\u001b[0m Trial 35 finished with value: 0.7582417582417582 and parameters: {'n_estimators': 38, 'max_depth': 3, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,766]\u001b[0m Trial 36 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 66, 'max_depth': 2, 'min_child_samples': 3}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,796]\u001b[0m Trial 37 finished with value: 0.7692307692307693 and parameters: {'n_estimators': 49, 'max_depth': 2, 'min_child_samples': 4}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-29 22:32:33,840]\u001b[0m Trial 38 finished with value: 0.7582417582417582 and parameters: {'n_estimators': 74, 'max_depth': 4, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,867]\u001b[0m Trial 39 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 32, 'max_depth': 3, 'min_child_samples': 3}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,909]\u001b[0m Trial 40 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 81, 'max_depth': 5, 'min_child_samples': 9}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,946]\u001b[0m Trial 41 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 53, 'max_depth': 2, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:33,975]\u001b[0m Trial 42 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 55, 'max_depth': 2, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:34,008]\u001b[0m Trial 43 finished with value: 0.7582417582417582 and parameters: {'n_estimators': 61, 'max_depth': 3, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:34,037]\u001b[0m Trial 44 finished with value: 0.8021978021978022 and parameters: {'n_estimators': 51, 'max_depth': 2, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:34,059]\u001b[0m Trial 45 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 45, 'max_depth': 2, 'min_child_samples': 3}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:34,099]\u001b[0m Trial 46 finished with value: 0.7802197802197802 and parameters: {'n_estimators': 57, 'max_depth': 3, 'min_child_samples': 3}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:34,159]\u001b[0m Trial 47 finished with value: 0.7032967032967034 and parameters: {'n_estimators': 66, 'max_depth': 7, 'min_child_samples': 4}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:34,191]\u001b[0m Trial 48 finished with value: 0.7582417582417582 and parameters: {'n_estimators': 44, 'max_depth': 4, 'min_child_samples': 8}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n",
      "\u001b[32m[I 2023-03-29 22:32:34,239]\u001b[0m Trial 49 finished with value: 0.7362637362637363 and parameters: {'n_estimators': 35, 'max_depth': 8, 'min_child_samples': 2}. Best is trial 12 with value: 0.8131868131868132.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hiperparámetros óptimos: {'n_estimators': 57, 'max_depth': 2, 'min_child_samples': 2}\n"
     ]
    }
   ],
   "source": [
    "#LIGHTGBM\n",
    "# Definir la función objetivo para optimizar.\n",
    "#cuidado: a mas parametros de tuneo en train pero es malo en test\n",
    "def objective(trial):\n",
    "    # Definir los rangos de búsqueda de los hiperparámetros\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100)# se sugieren valores desde el 10 al 100\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    min_child_samples = trial.suggest_int('min_child_samples', 2, 10)\n",
    "    \n",
    "    # Crear un clasificador Random Forest con los hiperparámetros seleccionados\n",
    "    clf = lgb.LGBMClassifier(n_estimators=n_estimators,\n",
    "                                  max_depth=max_depth,\n",
    "                                  min_child_samples=min_child_samples,\n",
    "                                  random_state=42)\n",
    "    \n",
    "    # Entrenar y evaluar el modelo\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Crear un objeto de estudio Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Ejecutar la optimización de hiperparámetros\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Obtener los hiperparámetros óptimos\n",
    "best_params = study.best_params\n",
    "print(f'Hiperparámetros óptimos: {best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf7d58dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8131868131868132\n"
     ]
    }
   ],
   "source": [
    "lg_model_tuneado =  lgb.LGBMClassifier(n_estimators=57, max_depth=2,min_child_samples=2)\n",
    "lg_model_tuneado.fit(X_train, y_train)\n",
    "y_pred = lg_model_tuneado.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e728d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7472527472527473\n"
     ]
    }
   ],
   "source": [
    "lg_model =  lgb.LGBMClassifier()\n",
    "lg_model.fit(X_train, y_train)\n",
    "y_pred = lg_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e48687",
   "metadata": {},
   "source": [
    "## Tarea\n",
    "\n",
    "#tarea hallar el mejor modelo para la prediccion de la diabetes utilizando nuestros codigos anterior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf07dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lsilvaa\\PycharmProjects\\Certusenero2023\\venv\\lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    " \n",
    "data = sklearn.datasets.fetch_openml(\"diabetes\", version=1, as_frame=True, return_X_y=False)\n",
    "data = data[\"frame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d367fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
